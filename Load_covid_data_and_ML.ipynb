{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('Gensim': conda)",
   "metadata": {
    "interpreter": {
     "hash": "accff395002211a42340e119a61d6c4579c71bfd5be8cd90bba04cb0233d8a5a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import fcsparser\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import zscore\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_covid_patients = ['export_COVID19 samples 23_04_20_ST3_COVID19_HC_001 ST3 230420_017_Live_cells.fcs',  'export_COVID19 samples 23_04_20_ST3_COVID19_HC_005 ST3 230420_016_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_HC_006 ST3 230420_015_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_HC_007 ST3 230420_014_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_HC_008 ST3 230420_013_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_HC_009 ST3 230420_012_Live_cells.fcs']\n",
    "\n",
    "ward_covid_patient = ['export_COVID19 samples 21_04_20_ST3_COVID19_ICU_changedW_019_O ST3 210420_040_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_changedW_027_O ST3 210420_039_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_changedW_036_O ST3 210420_035_Live_cells.fcs'  ,'export_COVID19 samples 21_04_20_ST3_COVID19_W_033_O ST3 210420_036_Live_cells.fcs',  'export_COVID19 samples 21_04_20_ST3_COVID19_W_042_O ST3 210420_032_Live_cells.fcs'  ,'export_COVID19 samples 21_04_20_ST3_COVID19_W_043_O ST3 210420_031_Live_cells.fcs',  'export_COVID19 samples 23_04_20_ST3_COVID19_W_001_O ST3 230420_037_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_010_O ST3 230420_033_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_011_O ST3 230420_032_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_012_O ST3 230420_031_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_014_O ST3 230420_029_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_015_O ST3 230420_028_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_016_O ST3 230420_027_Live_cells.fcs'  , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_017_O ST3 230420_026_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_018_O ST3 230420_025_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_020_O ST3 230420_007_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_022_O ST3 230420_006_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_024_O ST3 230420_005_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_025_O ST3 230420_004_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_026_O ST3 230420_003_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_029_O ST3 230420_002_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_046_O ST3 230420_011_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_W_048_O ST3 230420_010_Live_cells.fcs']\n",
    "\n",
    "ICU_covid_patient =['export_COVID19 samples 21_04_20_ST3_COVID19_ICU_005_A ST3 210420_080_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_013_A ST3 210420_078_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_014_A ST3 210420_073_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_015_A ST3 210420_069_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_023_A ST3 210420_064_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_027_A ST3 210420_061_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_029_A ST3 210420_059_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_031_A ST3 210420_055_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_036_A ST3 210420_053_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_039_A ST3 210420_051_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_043_A ST3 210420_049_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_045_A ST3 210420_045_Live_cells.fcs' , 'export_COVID19 samples 21_04_20_ST3_COVID19_ICU_changedW_002_O ST3 210420_043_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_002_A ST3 230420_052_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_003_A ST3 230420_049_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_006_A ST3 230420_046_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_012_A ST3 230420_043_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_025_A ST3 230420_039_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_changedW_004_O ST3 230420_036_Live_cells.fcs' , 'export_COVID19 samples 23_04_20_ST3_COVID19_ICU_changedW_049_O ST3 230420_009_Live_cells.fcs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(315187, 28)\n",
      "(363314, 28)\n",
      "(311492, 28)\n",
      "(183001, 28)\n",
      "(298047, 28)\n",
      "(248917, 28)\n",
      "(16808, 28)\n",
      "(4683, 28)\n",
      "(137169, 28)\n",
      "(365508, 28)\n",
      "(235332, 28)\n",
      "(245734, 28)\n",
      "(27390, 28)\n",
      "(155175, 28)\n",
      "(13767, 28)\n",
      "(22520, 28)\n",
      "(98608, 28)\n",
      "(68610, 28)\n",
      "(17164, 28)\n",
      "(186246, 28)\n",
      "(337833, 28)\n",
      "(266928, 28)\n",
      "(193497, 28)\n",
      "(15778, 28)\n",
      "(83002, 28)\n",
      "(13728, 28)\n",
      "(123154, 28)\n",
      "(364473, 28)\n",
      "(18618, 28)\n",
      "(170075, 28)\n",
      "(15792, 28)\n",
      "(139037, 28)\n",
      "(329393, 28)\n",
      "(185298, 28)\n",
      "(36744, 28)\n",
      "(271522, 28)\n",
      "(78856, 28)\n",
      "(61226, 28)\n",
      "(163885, 28)\n",
      "(173816, 28)\n",
      "(10959, 28)\n",
      "(17412, 28)\n",
      "(29363, 28)\n",
      "(10127, 28)\n",
      "(20956, 28)\n",
      "(58691, 28)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/admin/Desktop/FlowRepository_FR-FCM-Z2KP_files'\n",
    "\n",
    "threshold_number_cell = 3000\n",
    "healthy_patients = []\n",
    "for patient in healthy_covid_patients:\n",
    "    path = PATH + '/%s'%patient\n",
    "    meta, patient_file = fcsparser.parse(path, reformat_meta=True)\n",
    "    patient_file.drop(['FSC-A',\t'FSC-H',\t'FSC-W',\t'SSC-A',\t'SSC-H',\t'SSC-W', 'Time'], axis = 1, inplace = True)\n",
    "    if patient_file.shape[0] > threshold_number_cell:\n",
    "        healthy_patients.append(patient_file.apply(zscore).to_numpy())\n",
    "        print(patient_file.shape)\n",
    "\n",
    "ward_patients = []\n",
    "for patient in ward_covid_patient:\n",
    "    path = PATH + '/%s'%patient\n",
    "    meta, patient_file = fcsparser.parse(path, reformat_meta=True)\n",
    "    patient_file.drop(['FSC-A',\t'FSC-H',\t'FSC-W',\t'SSC-A',\t'SSC-H',\t'SSC-W', 'Time'], axis = 1, inplace = True)\n",
    "    if patient_file.shape[0] > threshold_number_cell:\n",
    "        ward_patients.append(patient_file.apply(zscore).to_numpy())\n",
    "        print(patient_file.shape)\n",
    "\n",
    "ICU_patients = []\n",
    "for patient in ICU_covid_patient:\n",
    "    path = PATH + '/%s'%patient\n",
    "    meta, patient_file = fcsparser.parse(path, reformat_meta=True)\n",
    "    patient_file.drop(['FSC-A',\t'FSC-H',\t'FSC-W',\t'SSC-A',\t'SSC-H',\t'SSC-W', 'Time'], axis = 1, inplace = True)\n",
    "    if patient_file.shape[0] > threshold_number_cell:\n",
    "        ICU_patients.append(patient_file.apply(zscore).to_numpy())\n",
    "        print(patient_file.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient = healthy_patients +  ward_patients + ICU_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "for i in range(len(healthy_patients)):\n",
    "    status.append(np.array(0))\n",
    "for i in range(len(ward_patients)):\n",
    "    status.append(np.array(1))\n",
    "for i in range(len(ICU_patients)):\n",
    "    status.append(np.array(2))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all_patient = [torch.from_numpy(item[:3000]).float() for item in all_patient]\n",
    "subset_all_patient_torch = torch.stack(subset_all_patient).to(device ='cuda')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([46, 3000, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "subset_all_patient_torch.size()"
   ]
  },
  {
   "source": [
    "all_patient_status = [torch.from_numpy(item).float() for item in status]\n",
    "all_patient_status_torch = torch.stack(all_patient_status).to(device ='cuda')#.unsqueeze(0)\n",
    "all_patient_status_torch.size()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([46])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([46, 3000, 28]) torch.Size([46])\n"
     ]
    }
   ],
   "source": [
    "print(subset_all_patient_torch.size(),all_patient_status_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_covid_patients = TensorDataset(subset_all_patient_torch,all_patient_status_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dataset_covid_patients)  # how many total elements you have\n",
    "n_test = int( n * 0.4 )  # number of test/val elements\n",
    "n_train = n - 4 * n_test\n",
    "idx = list(range(n))  # indices to all elements\n",
    "random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "train_idx = idx[:n_train]\n",
    "val_idx = idx[n_train:(n_train + n_test)]\n",
    "test_idx = idx[(n_train + n_test):]\n",
    "\n",
    "train_set = Subset(dataset_covid_patients, train_idx)\n",
    "val_set = Subset(dataset_covid_patients, val_idx)\n",
    "test_set = Subset(dataset_covid_patients, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_covid = DataLoader(dataset=train_set, shuffle=True)\n",
    "val_set_covid = DataLoader(dataset=val_set, shuffle=True)\n",
    "test_set_covid = DataLoader(dataset=test_set, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUIL(nn.Module):\n",
    "    \n",
    "    input_size = [3000, 28]\n",
    "    output_size = 1\n",
    "    input_channels = 1\n",
    "    channels_conv1 = 3\n",
    "    channels_conv2 = 3\n",
    "    kernel_conv1 = [3, 1]\n",
    "    kernel_conv2 = [1, 1]\n",
    "    pool_conv1 = [2, 2]\n",
    "    pool_conv2 = [1, 2]\n",
    "    fcl1_size = 50\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvUIL, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.input_channels, self.channels_conv1, self.kernel_conv1)\n",
    "        self.conv2 = nn.Conv1d(self.channels_conv1, self.channels_conv2, self.kernel_conv2)\n",
    "        \n",
    "        # Calculate the convolutional layers output size (stride = 1)\n",
    "        c1 = np.array(self.input_size) - self.kernel_conv1 + 1\n",
    "        p1 = c1 // self.pool_conv1\n",
    "        c2 = p1 - self.kernel_conv2 + 1\n",
    "        p2 = c2 // self.pool_conv2\n",
    "        self.conv_out_size = int(p2[0] * p2[1] * self.channels_conv2)\n",
    "\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fcl1 = nn.Linear(self.conv_out_size, self.fcl1_size)\n",
    "        self.fcl2 = nn.Linear(self.fcl1_size, self.output_size)\n",
    "     \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolution 1 and pooling\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, self.pool_conv1)\n",
    "        \n",
    "        # Apply convolution 2 and pooling\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, self.pool_conv2)\n",
    "        \n",
    "        # Reshape x to one dimmension to use as input for the fully connected layers\n",
    "        x = x.view(-1, self.conv_out_size)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fcl1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fcl2(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ConvUIL(\n  (conv1): Conv1d(1, 3, kernel_size=[3, 1], stride=(1,))\n  (conv2): Conv1d(3, 3, kernel_size=[1, 1], stride=(1,))\n  (fcl1): Linear(in_features=31479, out_features=50, bias=True)\n  (fcl2): Linear(in_features=50, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "convUIL = ConvUIL()\n",
    "print(convUIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.25\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(convUIL.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-616276c82c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvUIL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Gensim\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-990a78ef43be>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Apply convolution 1 and pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_conv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Gensim\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Gensim\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Gensim\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 259\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    260\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    loss_array = []\n",
    "    val_loss_array = []\n",
    "\n",
    "    for i, (observations, labels) in enumerate(train_set_covid):\n",
    "        convUIL.train()\n",
    "\n",
    "        observations = Variable(observations.cuda()).unsqueeze(0)\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = convUIL(observations).squeeze(0).squeeze(0)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "    for i, (observations, labels_val) in enumerate(val_set_covid):\n",
    "        convUIL.eval()\n",
    "\n",
    "        observations_val = Variable(observations).unsqueeze(0).unsqueeze(0)\n",
    "        labels_val = Variable(labels).cuda()\n",
    "\n",
    "\n",
    "        outputs_val = convUIL(observations_val).squeeze(0).squeeze(0)\n",
    "        val_loss = criterion(outputs_val, labels_val)\n",
    "        val_loss_array.append(val_loss.item())\n",
    "               \n",
    "    print('Epoch [%2d/%2d]'%(epoch + 1, epochs), 'loss = %s'%np.mean(loss_array), 'val_loss = %s'%np.mean(val_loss_array)) "
   ]
  }
 ]
}